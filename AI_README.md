# 強化学習AI実装ガイド

## 概要

このプロジェクトに強化学習（Q-Learning）ベースの敵AIを実装しました。**全ての敵（通常敵・ボス含む）**がプレイヤーとの戦闘を通じて、より賢い行動パターンを学習します。

### 特徴
- **サーバー管理の敵もAI制御**: クライアント側でAIが動作し、その結果をサーバーに送信
- **学習データの永続化**: localStorageに保存され、リロード後も学習が継続
- **リアルタイム統計表示**: 複数の敵の学習状況を平均化して表示

## 実装されたコンポーネント

### 1. QLearningAgent (`client/ai/QLearningAgent.js`)
- Q-Learningアルゴリズムの実装
- 状態の離散化と行動選択
- ε-greedy法による探索と活用のバランス
- 学習データのlocalStorageへの保存/読み込み

### 2. EnemyAI (`client/ai/EnemyAI.js`)
- 敵の行動制御
- 状態の観測（プレイヤーとの距離、HP、角度など）
- 報酬の計算
- 行動の実行（接近、回避、回り込みなど）

### 3. AIStatsUI (`client/ui/AIStatsUI.js`)
- AI学習状況の可視化
- リアルタイム統計表示

## 敵の行動パターン

AIは以下の6つの行動から選択します：

1. **approach** - プレイヤーに接近
2. **retreat** - プレイヤーから逃げる
3. **circle_left** - 左に回り込む
4. **circle_right** - 右に回り込む
5. **aggressive** - 積極的攻撃（高速接近）
6. **wait** - 待機

## 学習メカニズム

### 状態の定義
- プレイヤーとの距離（4段階）
- 敵のHP割合（4段階）
- プレイヤーのHP割合（4段階）
- プレイヤーへの方向（8方向）

### 報酬設計
- **生存報酬**: +0.1（毎フレーム）
- **適切な距離維持**: +0.5
- **攻撃範囲内（HP高い時）**: +2
- **攻撃範囲内（HP低い時）**: -1
- **遠すぎる**: -0.5
- **ダメージを受ける**: -0.1 × ダメージ量
- **ダメージを与える**: +0.5 × ダメージ量
- **死亡**: -10

## 使い方

### 基本操作

1. **ゲーム起動**
   - 敵は自動的にAIモードで動作します
   - 学習データはlocalStorageに保存されます

2. **AI統計表示**
   - `Shift + A`: AI学習統計の表示/非表示
   - 表示内容:
     - Active AI: アクティブなAI敵の数
     - Epsilon: 探索率（低いほど学習済み）
     - Episodes: 学習エピソード数
     - Avg Reward: 平均報酬
     - Q-Table: 学習済み状態数

3. **学習モード切り替え**
   - `Shift + T`: 学習モードのON/OFF
   - OFF: 学習済みの行動のみ使用（探索なし）
   - ON: 新しい行動を探索しながら学習

### 学習の進行

1. **初期段階（Epsilon: 0.3）**
   - ランダムな行動が多い
   - 様々な状況を経験

2. **中期段階（Epsilon: 0.1-0.2）**
   - 基本的な戦術を習得
   - 距離の取り方を学習

3. **後期段階（Epsilon: 0.05-0.1）**
   - 洗練された行動パターン
   - 状況に応じた最適な行動

## カスタマイズ

### AIパラメータの調整

`Enemy.js`のコンストラクタで設定を変更できます：

```javascript
this.ai = new EnemyAI(this, {
    isTraining: true,        // 学習モード
    actionInterval: 500,     // 行動更新間隔（ms）
    learningRate: 0.1,       // 学習率（0-1）
    epsilon: 0.3,            // 初期探索率
    epsilonDecay: 0.995,     // 探索率減衰
    minEpsilon: 0.05         // 最小探索率
});
```

### 報酬の調整

`EnemyAI.js`の`calculateReward`メソッドで報酬を調整できます。

### 新しい行動の追加

`QLearningAgent.js`の`actions`配列に追加し、`EnemyAI.js`の`executeAction`メソッドに実装を追加します。

## トラブルシューティング

### 敵が動かない
- ブラウザのコンソールでエラーを確認
- AIが有効になっているか確認（`enemy.useAI`）

### 学習が進まない
- 探索率（Epsilon）が低すぎる可能性
- 報酬設計を見直す
- localStorageをクリアして再学習

### パフォーマンス問題
- `actionInterval`を増やす（500ms → 1000ms）
- 同時に動作するAI敵の数を制限

## 今後の拡張案

1. **協調行動**
   - 複数の敵が連携して攻撃
   - 役割分担（タンク、アタッカー、サポート）

2. **Deep Q-Learning**
   - ニューラルネットワークの導入
   - より複雑な状態表現

3. **転移学習**
   - 異なる敵タイプ間で学習を共有
   - 強い敵から弱い敵へ知識を転移

4. **対戦モード**
   - プレイヤー vs AI
   - AI同士の対戦

## 技術詳細

### Q-Learning更新式

```
Q(s,a) ← Q(s,a) + α[r + γ max Q(s',a') - Q(s,a)]
```

- α: 学習率（0.1）
- γ: 割引率（0.95）
- r: 即時報酬
- s: 現在の状態
- a: 選択した行動
- s': 次の状態

### ε-greedy法

```
行動選択 = {
    ランダム行動  (確率 ε)
    最適行動      (確率 1-ε)
}
```

## ライセンス

このAI実装は、プロジェクトのメインライセンスに従います。
